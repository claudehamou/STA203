---
title: "Projet STA203"
author: "Hamou Claude, Ray Loic"
date: "25/04/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(ggplot2)
library(GGally)
library(caret)
```



Dans ce projet nous allons étudier un jeu de données musical. Ce jeu de données contient 191 variable quantitatives et 1 variables qualitative qui représente le genre de musique. Nous allons implémenter 3 méthodes permettant de prédire la variable de genre à partir des autres variables.
Commençons donc par importer le jeu de données.
```{r}
data=read.table("Music.txt", header = TRUE, sep=";")
#head(data)
#summary(data) #trop long
#str(data)
ncol(data) #nombre de variable
nrow(data) #nombre d'observation
```

# Partie 1

## Question 1

Il y a trop de variables pour pouvoir extraire des informations en regardant les données bruts.
Mais on peut toutefois faire des analyses univariée et bivariée sur quelques variables.

Regardons tout d'abord le nombre d'individu de chaque classe.
```{r}
summary(data[192]) #nombre de d'individu de chaque groupes
```
On peut déjà remarquer que le jeu de données est relativement équilibrés, ce qui nous permet de faire une étude qui ne soit pas trop biaisée.

Faisons une analyse univariée, sans considérer la variable qualitative 192.
```{r fig.height=4, fig.width=10}
boxplot(data[-192])
```
Cela ne ce voit pas bien sur le graphique mais les variables 3 **PAR_SC_V** , et 179 **PAR_PEAK_RMS10FR_VAR** prennent des valeurs bien plus élevées que les autres variables. On peut notamment remarquer que ces deux variables ont des variances élevées (du fait de la répartions des points au dessus de leur boites)
Affichons un nouveau boxplot sans prendre en compte ces variables.

```{r fig.height=4, fig.width=10}
boxplot(data[-c(3,179,192)])
#boxplot((data[c(-3,-179,-192)])[2:10])
```
Nous voyons ici que les variables et 2 **PAR_SC** et 178 **PAR_PEAK_RMS10FR_MEAN** prennent elles aussi des valeurs bien supérieures aux autres variables, avec là encore une grande variance entre les valeurs. Par ailleurs cela n'est pas étonnant car ces variables et les variables précédentes sont reliées. En effet les variables que nous avons ici représente des moyennes, et les variables précédetent représentaient la variance associée. 

Faisons un dernier boxplot sans ces variables.  

**ON POURRAIT FAIRE UN TRUC MIEUX EN ECRIVANT UNE FONCTION QUI RENVOIE LE NOMS DE TOUTES LES VARIAVLES QUI PRENNENT DES VALEURS SUPERIEURES A UNE CONSTANT GENRE 1**

```{r fig.height=4, fig.width=10}
boxplot(data[-c(2,3,178,179,192)])
#boxplot((data[-c(2,3,178,179,192)])[175:180])
```


Interessons nous maintenant aux corrélations entre les variable, en faisant une étude bivariée du jeu de données.
Pour cela calculons et affichons la matrice de corrélations.

```{r fig.height=5}
matrice_data=data.matrix(data)
correlation_data=cor(matrice_data)
ggcorr(matrice_data,nbreaks = 4, palette = "RdGy")
#corrplot(correlation_data, tl.pos='n')
```
Comme cela était attendu, le graphique est quasiment illisible. Mais on parvient tout de même à diserner des zones de forte covariance.
Implementons une fonction qui affiche les variables dont la covariance est comprise entre 2 bornes, afin de retirer des informations plus pertinentes de la matrice de corrélation.
```{r}
print_corr_borne= function(mat_cor,seuil_min,seuil_max){
  l=nrow(mat_cor)
  found=FALSE
  for(i in 1:l){
    for(j in 1:i){
      if(mat_cor[i,j]>seuil_min &&mat_cor[i,j]<seuil_max){
        #Affiche le nom des variables correspondantes
        found=TRUE
        print(names(data)[c(i,j)])
      }
    }
  }
  if(!found){
    print("Il n'y a aucune covariance n'est comprise entre ces bornes")
  }
}
```

Nous pouvons alors afficher les variables trés corrélées, dont la covariance se trouve dans $\big]0.99;1\big[$
```{r}
print_corr_borne(correlation_data,0.99,1)
```

Ainsi que les variables trés anti-corrélées, dont la covariance se trouve dans $\big]-1;0.99\big[$
```{r}
print_corr_borne(correlation_data,-1,-0.99)
```

On remarque donc que les variables très corrélées sont de type *MFCCV* et *MFCC* ainsi que des variables *ASE*.





Considérons les variables 128 à 147 et 148 à 167. En regardant le jeu de données et son déscriptif, il semblerait que ces deux groupes de variables soient égaux.
Pour le confirmer on écrit un script qui renvoie le nombre de différence entre ces 2 groupes.

```{r}
#Egalite 128:147 et 148:167
dif=0
for(i in 128:147){
  dif=sum(data[i]!=data[i+20])
}
dif
```

Comme indiqué dans le descriptif du dataset, les colonnes 128 à 147 et 148 à 167 ont les mêmes valeurs. On ne considèrera donc pas les colonnes 148 à 167 dans la suite.



Les données **PAR_ASE_M**, **PAR_ASE_MV**, **PAR_SFM_M** et **PAR_SFM_MV** représentent les moyennes des variables 4 à 37, 39 à 72, 78 à 101, et 103 à 126. Pour réduire le nombre de variable il peut être préférable dans un premier temps de pas considéré les colonnes 4 à 37, 39 à 72, 78 à 101, et 103 à 126 comme les variables **PAR_ASE_M**, **PAR_ASE_MV**, **PAR_SFM_M** et **PAR_SFM_MV** en sont des agréats.



On réalise les opérations de nettoyage précédement expliquées et on note *X* le nouveau data frame de données que nous allons utiliser dans la suite.
Et *Y* le vecteur contenant la variable qualitative **GENRE** en binaire, avec $Classical = 0$ et $Jazz = 1$.

```{r}
#Colonnes que nous n'utiliserons pas dans la suite
del=c(148:167,
      4:37,
      39:72,
      78:101,
      103:126)
#
X=data[,-c(del,192)]
#log des variables PAR_SC_V et PAR_ASC_V
X["PAR_SC_V"]=log(data["PAR_SC_V"])
X["PAR_ASC_V"]=log(data["PAR_ASC_V"])

#
GENRE=data[,192]
Y=1*(GENRE=="Jazz")
```



Nous cherchons à déterminer un modèle logistique permettant de d'estimer les valeurs de la variable **Y**.
Cette variable prend deux valeurs **0** et **1**.

**MODELE BERNOULLI...**
**A ECRIRE**




## Question 2

On utilise le code proposé pour générer des data-frame de *training* permettant de fitter le modèle et des data-frame de *test*.

```{r}
set.seed(103)
n=nrow(data)
train=sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
X_training=X[train,]
X_test=X[!train,]

GENRE_training=GENRE[train]
GENRE_test=GENRE[!train]

Y_training=Y[train]
Y_test=Y[!train]
```



## Question 3

### Mod0 

```{r}
indices=c("PAR_TC","PAR_SC", "PAR_SC_V", "PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV")
Mod0=glm(Y_training~.,family=binomial,data=X_training[indices])
summary(Mod0)
par(mfrow=c(2,2)) 
plot(Mod0)
Mod0.predict=predict(Mod0, newdata=X_test[indices], type="response")
```

### ModT

```{r}
ModT=glm(Y_training~.,family=binomial,data=X_training)
summary(ModT)
par(mfrow=c(2,2))
plot(ModT)
ModT.predict=predict(ModT, newdata=X_test, type="response")
```

### Mod1

```{r}
#Pr(>|t|)  de ModT
ModT.p_val=coef(summary(ModT))[,4]
#On cherche les indices de p-value < 5%
indice_sign_5=names(which(ModT.p_val<0.05))
#Prediction de Mod1
Mod1=glm(Y_training~.,family=binomial,data=X_training[indice_sign_5])
summary(Mod1)
par(mfrow=c(2,2))
plot(Mod1)
ModT.predict=predict(Mod1, newdata=X_test[indice_sign_5], type="response")
```

### Mod2 
```{r}
#Pr(>|t|)  de ModT
ModT.p_val=coef(summary(ModT))[,4]
#On cherche les indices de p-value < 20%
indice_sign_20=names(which(ModT.p_val<0.2))[c(-1)] #car 1er element est l'intercept
#Prediction de Mod1
Mod2=glm(Y_training~.,family=binomial,data=X_training[indice_sign_20])
summary(Mod2)
par(mfrow=c(2,2))
plot(Mod2)
ModT.predict=predict(Mod2, newdata=X_test[indice_sign_20], type="response")
```

### ModAIC





# Partie 2

## Question 1: K-NN

La méthode des k plus proches voisins (knn ou k nearest neighbours) est une méthode simple à utiliser dans des cas de classification ou régression. Il s'agit d'une méthode non paramétrique dans laquelle le modèle mémorise les observations de l'ensemble d'apprentissage et s'en sert pour les observations des données de test. Elle consiste à fixer un nombre k de voisins des nouvelles données d'entrée, de séléctionner les k plus proches (en fonction d'une certaine distance, la distance euclidienne par exemple) et de conserver la classe correspondant à celle majoritairement représentée parmi les différents voisins retenus.

Pour choisir le meilleur k, il faut tester différentes valeurs et retenir celle qui minimise le taux d'erreur de l'ensemble de test.

## Question 2: Implémentation K-NN

```{r}
library(class)

```

